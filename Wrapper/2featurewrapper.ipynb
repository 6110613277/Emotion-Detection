{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5gC1H--zkJJ"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.feature import hog\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import glob, random, math, numpy as np, dlib, itertools\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "#binarize the y_values\n",
    "#Lets encode target labels (y) with values between 0 and n_classes-1.\n",
    "#We will use the LabelEncoder to do this. \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8-FYLln0mJ7"
   },
   "outputs": [],
   "source": [
    "# ใส่ ข้อมูลตรงนี้\n",
    "# เปลี่ยน path\n",
    "\n",
    "#X3 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/features_GABOR.npy') \n",
    "#y3 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/labels_GABOR.npy')\n",
    "\n",
    "X4 = np.load('/content/drive/MyDrive/feature_new3/features_HLAC.npy') \n",
    "y4 = np.load('/content/drive/MyDrive/feature_new3/labels_HLAC.npy')\n",
    "\n",
    "#X5 = np.load('/content/drive/MyDrive/feature_new3/features_HOG.npy') \n",
    "#y5 = np.load('/content/drive/MyDrive/feature_new3/labels_HOG.npy')\n",
    "\n",
    "X1 = np.load('/content/drive/MyDrive/feature_new3/features_LAND3.npy',allow_pickle=True) \n",
    "y1 = np.load('/content/drive/MyDrive/feature_new3/labels_LAND3.npy')\n",
    "\n",
    "#X2 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/features_LBP.npy') \n",
    "#y2 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/labels_LBP.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy3cVPTnRlV2"
   },
   "outputs": [],
   "source": [
    "X2 = numpy.array(X2)\n",
    "nsamples, nx, ny = X2.shape\n",
    "X2 = X2.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-KGKBsU7T8W"
   },
   "outputs": [],
   "source": [
    "df_L =  pd.DataFrame(X1)\n",
    "df_LB =  pd.DataFrame(X2)\n",
    "df_G = pd.DataFrame(X3)\n",
    "df_H =  pd.DataFrame(X4)\n",
    "df_HO =  pd.DataFrame(X5)\n",
    "\n",
    "df_L_L =  pd.DataFrame(y1)\n",
    "df_LB_L =  pd.DataFrame(y2)\n",
    "df_G_L =  pd.DataFrame(y3)\n",
    "df_H_L =  pd.DataFrame(y4)\n",
    "df_HO_L =  pd.DataFrame(y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2sC5LwV8BFQ"
   },
   "outputs": [],
   "source": [
    "df_L_L.columns = [ 'LABEL1'  ]\n",
    "df_LB_L.columns = [ 'LABEL1'  ]\n",
    "df_G_L.columns = [ 'LABEL1'  ]\n",
    "df_H_L.columns = [ 'LABEL1'  ]\n",
    "df_HO_L.columns = [ 'LABEL1'  ]\n",
    "\n",
    "df_L.columns = [ 'LAND_LIST' ]\n",
    "df_LB.columns = [ 'LBP' + str(i + 1) for i in range(len(df_LB.columns)) ]\n",
    "df_G.columns = [ 'GABOR' + str(i + 1) for i in range(len(df_G.columns)) ]\n",
    "df_H.columns = [ 'HLAC' + str(i + 1) for i in range(len(df_H.columns)) ]\n",
    "df_HO.columns = [ 'HOG' + str(i + 1) for i in range(len(df_HO.columns)) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0npTH_izSIp_"
   },
   "outputs": [],
   "source": [
    "X1X2 = pandas.concat([df_L_L, df_L, df_LB], axis=1, join=\"inner\")\n",
    "X1X3 = pandas.concat([df_L_L, df_L, df_G], axis=1, join=\"inner\")\n",
    "X1X4 = pandas.concat([df_L_L, df_L, df_H], axis=1, join=\"inner\")\n",
    "X1X5 = pandas.concat([df_L_L, df_L, df_HO], axis=1, join=\"inner\")\n",
    "\n",
    "X2X3 = pandas.concat([df_LB_L, df_LB, df_G], axis=1, join=\"inner\")\n",
    "X2X4 = pandas.concat([df_LB_L, df_LB, df_H], axis=1, join=\"inner\")\n",
    "X2X5 = pandas.concat([df_LB_L, df_LB, df_HO], axis=1, join=\"inner\")\n",
    "\n",
    "X3X4 = pandas.concat([df_G_L, df_G, df_H], axis=1, join=\"inner\")\n",
    "X3X5 = pandas.concat([df_G_L, df_G, df_HO], axis=1, join=\"inner\")\n",
    "\n",
    "X4X5 = pandas.concat([df_H_L, df_H, df_HO], axis=1, join=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S__aV8Bp9fl1"
   },
   "outputs": [],
   "source": [
    "X1X2['LAND_LIST'] = X1X2['LAND_LIST'].replace('error', np.nan)\n",
    "X1X3['LAND_LIST'] = X1X3['LAND_LIST'].replace('error', np.nan)\n",
    "X1X4['LAND_LIST'] = X1X4['LAND_LIST'].replace('error', np.nan)\n",
    "X1X5['LAND_LIST'] = X1X5['LAND_LIST'].replace('error', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxIJBxxVFTAP"
   },
   "outputs": [],
   "source": [
    "df1 = X1X2\n",
    "df2 = X1X3\n",
    "df3 = X1X4\n",
    "df4 = X1X5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwvmoPmrFV_z",
    "outputId": "9fb63ec3-eb98-4d6b-9c71-5a62dcaf499a"
   },
   "outputs": [],
   "source": [
    "df1 = df1.dropna()\n",
    "df2 = df2.dropna()\n",
    "df3 = df3.dropna()\n",
    "df4 = df4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcqW_z_xUIGa"
   },
   "outputs": [],
   "source": [
    "df1['LAND_LISTSTING'] = [','.join(map(str, l)) for l in df1['LAND_LIST']]\n",
    "df2['LAND_LISTSTING'] = [','.join(map(str, l)) for l in df2['LAND_LIST']]\n",
    "df3['LAND_LISTSTING'] = [','.join(map(str, l)) for l in df3['LAND_LIST']]\n",
    "df4['LAND_LISTSTING'] = [','.join(map(str, l)) for l in df4['LAND_LIST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQRl8IJ4Ksvv"
   },
   "outputs": [],
   "source": [
    "df5 = df1['LAND_LISTSTING'].str.split(',', expand=True)\n",
    "df6 = df2['LAND_LISTSTING'].str.split(',', expand=True)\n",
    "df7 = df3['LAND_LISTSTING'].str.split(',', expand=True)\n",
    "df8 = df4['LAND_LISTSTING'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PA0KBPGUjp1"
   },
   "outputs": [],
   "source": [
    "df5.columns = [ 'LAND' + str(i + 1) for i in range(len(df5.columns)) ]\n",
    "df6.columns = [ 'LAND' + str(i + 1) for i in range(len(df6.columns)) ]\n",
    "df7.columns = [ 'LAND' + str(i + 1) for i in range(len(df7.columns)) ]\n",
    "df8.columns = [ 'LAND' + str(i + 1) for i in range(len(df8.columns)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XpfsHavUuOM"
   },
   "outputs": [],
   "source": [
    "final_df1 = pandas.concat([df1,df5], axis=1, join=\"inner\")\n",
    "final_df2 = pandas.concat([df2,df6], axis=1, join=\"inner\")\n",
    "final_df3 = pandas.concat([df3,df7], axis=1, join=\"inner\")\n",
    "final_df4 = pandas.concat([df4,df8], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fg91Fsk_F0qA"
   },
   "outputs": [],
   "source": [
    "X1X2 = final_df1.drop(['LABEL1', 'LAND_LIST','LAND_LISTSTING'], axis = 1)\n",
    "y1y2 = final_df1['LABEL1']\n",
    "\n",
    "X1X3 = final_df2.drop(['LABEL1', 'LAND_LIST','LAND_LISTSTING'], axis = 1)\n",
    "y1y3 = final_df2['LABEL1']\n",
    "\n",
    "X1X4 = final_df3.drop(['LABEL1', 'LAND_LIST','LAND_LISTSTING'], axis = 1)\n",
    "y1y4 = final_df3['LABEL1']\n",
    "\n",
    "X1X5 = final_df4.drop(['LABEL1', 'LAND_LIST','LAND_LISTSTING'], axis = 1)\n",
    "y1y5 = final_df4['LABEL1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYpV6Ec5RQY8"
   },
   "source": [
    "#Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vw_JMxVpRSvS"
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBVmZC7URUIH"
   },
   "outputs": [],
   "source": [
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    normalize:     If True, show the proportions for each category. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "    cm1 = cf.astype(np.float64) / cf.sum(axis=1)[:, np.newaxis]\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = ['{:.2f}'.format(value) for value in cm1.flatten()]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwQ_yxM7RWMp"
   },
   "outputs": [],
   "source": [
    "def model_roc_curve(X, y, model, cv):\n",
    "    #ส่วน f.confusion matrix\n",
    "    def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        if not title:\n",
    "            if normalize:\n",
    "                title = 'Normalized confusion matrix'\n",
    "            else:\n",
    "                title = 'Confusion matrix, without normalization'\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm1 = confusion_matrix(y_true, y_pred)\n",
    "        # Only use the labels that appear in the data\n",
    "        classes = classes\n",
    "        if normalize:\n",
    "            cm = cm1.astype('float') / cm1.sum(axis=1)[:, np.newaxis]\n",
    "            #print(\"Normalized confusion matrix\")\n",
    "        #else:\n",
    "            #print('Confusion matrix, without normalization')\n",
    "\n",
    "        #print(cm)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12,6))\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        # We want to show all ticks...\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "               # ... and label them with the respective list entries\n",
    "               xticklabels=classes, yticklabels=classes,\n",
    "               title=title,\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig.tight_layout()\n",
    "        return ax\n",
    "\n",
    "    #ตัวเเปร 5 fold สำหรับ roc curve\n",
    "    fig1 = plt.figure(figsize=[8, 8])\n",
    "    mean_score = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    y_testanger = []\n",
    "    X_testanger = []\n",
    "    \n",
    "    fpr1 = []\n",
    "    tpr1 = []\n",
    "    roc_auc1 = []\n",
    "    tprs1 = []\n",
    "    aucs1 = []\n",
    "    mean_fpr1 = np.linspace(0, 1, 100)\n",
    "\n",
    "    fpr2 = []\n",
    "    tpr2 = []\n",
    "    roc_auc2 = []\n",
    "    tprs2 = []\n",
    "    aucs2 = []\n",
    "    mean_fpr2 = np.linspace(0, 1, 100)\n",
    "\n",
    "    fpr3 = []\n",
    "    tpr3 = []\n",
    "    roc_auc3 = []\n",
    "    tprs3 = []\n",
    "    aucs3 = []\n",
    "    mean_fpr3 = np.linspace(0, 1, 100)\n",
    "\n",
    "    fpr4= []\n",
    "    tpr4= []\n",
    "    roc_auc4= []\n",
    "    tprs4 = []\n",
    "    aucs4 = []\n",
    "    mean_fpr4 = np.linspace(0, 1, 100)\n",
    "\n",
    "    fpr5= []\n",
    "    tpr5= []\n",
    "    roc_auc5= []\n",
    "    tprs5 = []\n",
    "    aucs5 = []\n",
    "    mean_fpr5 = np.linspace(0, 1, 100)\n",
    "\n",
    "    fpr6= []\n",
    "    tpr6= []\n",
    "    roc_auc6= []\n",
    "    tprs6 = []\n",
    "    aucs6 = []\n",
    "    mean_fpr6 = np.linspace(0, 1, 100)\n",
    "\n",
    "    fpr7= []\n",
    "    tpr7= []\n",
    "    roc_auc7= []\n",
    "    tprs7 = []\n",
    "    aucs7 = []\n",
    "    mean_fpr7 = np.linspace(0, 1, 100)\n",
    "    \n",
    "    \n",
    "    fpr8= []\n",
    "    tpr8= []\n",
    "    roc_auc8= []\n",
    "    tprs8 = []\n",
    "    aucs8 = []\n",
    "    mean_fpr8 = np.linspace(0, 1, 100)\n",
    "\n",
    "    #parameter for find SD \n",
    "    sumAcc_anger =[]\n",
    "    sumAcc_contempt =[]\n",
    "    sumAcc_disgust =[]\n",
    "    sumAcc_fear = []\n",
    "    sumAcc_hapiness = []\n",
    "    sumAcc_neutral = []\n",
    "    sumAcc_sad = []\n",
    "    sumAcc_surprise = []\n",
    "    i = 0\n",
    "    num = 1\n",
    "\n",
    "    #เริ่มเเบ่ง fold\n",
    "    for train, test in cv.split(X, y):\n",
    "        X_train = X[train]\n",
    "        X_test = X[test]\n",
    "        y_train = y[train]\n",
    "        y_test = y[test]\n",
    "        y_testanger = []\n",
    "        X_testanger = []\n",
    "        model.fit(X_train, y_train)\n",
    "        lw = 2\n",
    "        y_test_binarized=label_binarize(y_test,classes=np.unique(y_test))\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        #ค่า accuracy 5 fold crossval\n",
    "        #accuracy = cross_val_score(model, X, y, scoring='accuracy', cv=cv)\n",
    "\n",
    "        fpr = {}\n",
    "        tpr = {}\n",
    "        thresh ={}\n",
    "        roc_auc = dict()\n",
    "        classes=np.unique(y_test)\n",
    "        n_class = classes.shape[0]\n",
    "\n",
    "        #เก็บค่า fpr tpr เเต่ละอารมณ์ เเต่ละ fold\n",
    "        fpr[0], tpr[0], _ = roc_curve(y_test_binarized[:,0],y_pred[:,0])\n",
    "        fpr1.append(fpr[0])\n",
    "        tpr1.append(tpr[0])\n",
    "        tprs1.append(np.interp(mean_fpr1, fpr[0], tpr[0])) #ไว้ใช้หาค่า mean\n",
    "        roc_auc[0] = auc(fpr[0], tpr[0])\n",
    "        roc_auc1.append(roc_auc[0])\n",
    "        aucs1.append(roc_auc[0]) #ไว้ใช้หาค่า std\n",
    "        \n",
    "        fpr[1], tpr[1], _ = roc_curve(y_test_binarized[:,1],y_pred[:,1])\n",
    "        fpr2.append(fpr[1])\n",
    "        tpr2.append(tpr[1])\n",
    "        tprs2.append(np.interp(mean_fpr2, fpr[1], tpr[1]))\n",
    "        roc_auc[1] = auc(fpr[1], tpr[1])\n",
    "        roc_auc2.append(roc_auc[1])\n",
    "        aucs2.append(roc_auc[1]) \n",
    "        \n",
    "        fpr[2], tpr[2], _ = roc_curve(y_test_binarized[:,2],y_pred[:,2])\n",
    "        fpr3.append(fpr[2])\n",
    "        tpr3.append(tpr[2])\n",
    "        tprs3.append(np.interp(mean_fpr3, fpr[2], tpr[2]))\n",
    "        roc_auc[2] = auc(fpr[2], tpr[2])\n",
    "        roc_auc3.append(roc_auc[2])\n",
    "        aucs3.append(roc_auc[2])\n",
    "        \n",
    "        fpr[3], tpr[3], _ = roc_curve(y_test_binarized[:,3],y_pred[:,3])\n",
    "        fpr4.append(fpr[3])\n",
    "        tpr4.append(tpr[3])\n",
    "        tprs4.append(np.interp(mean_fpr4, fpr[3], tpr[3]))\n",
    "        roc_auc[3] = auc(fpr[3], tpr[3])\n",
    "        roc_auc4.append(roc_auc[3])\n",
    "        aucs4.append(roc_auc[3]) \n",
    "        \n",
    "        fpr[4], tpr[4], _ = roc_curve(y_test_binarized[:,4],y_pred[:,4])\n",
    "        fpr5.append(fpr[4])\n",
    "        tpr5.append(tpr[4])\n",
    "        tprs5.append(np.interp(mean_fpr5, fpr[4], tpr[4]))\n",
    "        roc_auc[4] = auc(fpr[4], tpr[4])\n",
    "        roc_auc5.append(roc_auc[4])\n",
    "        aucs5.append(roc_auc[4]) \n",
    "        \n",
    "        fpr[5], tpr[5], _ = roc_curve(y_test_binarized[:,5],y_pred[:,5])\n",
    "        fpr6.append(fpr[5])\n",
    "        tpr6.append(tpr[5])\n",
    "        tprs6.append(np.interp(mean_fpr6, fpr[5], tpr[5]))\n",
    "        roc_auc[5] = auc(fpr[5], tpr[5])\n",
    "        roc_auc6.append(roc_auc[5])\n",
    "        aucs6.append(roc_auc[5]) \n",
    "        \n",
    "        fpr[6], tpr[6], _ = roc_curve(y_test_binarized[:,6],y_pred[:,6])\n",
    "        fpr7.append(fpr[6])\n",
    "        tpr7.append(tpr[6])\n",
    "        tprs7.append(np.interp(mean_fpr7, fpr[6], tpr[6]))\n",
    "        roc_auc[6] = auc(fpr[6], tpr[6])\n",
    "        roc_auc7.append(roc_auc[6])\n",
    "        aucs7.append(roc_auc[6])\n",
    "        \n",
    "        fpr[7], tpr[7], _ = roc_curve(y_test_binarized[:,7],y_pred[:,7])\n",
    "        fpr8.append(fpr[7])\n",
    "        tpr8.append(tpr[7])\n",
    "        tprs8.append(np.interp(mean_fpr8, fpr[7], tpr[7]))\n",
    "        roc_auc[7] = auc(fpr[7], tpr[7])\n",
    "        roc_auc8.append(roc_auc[7])\n",
    "        aucs8.append(roc_auc[7])\n",
    "\n",
    "        #save models\n",
    "        #filename = \"Model_LAND :\" + \"Random\" + str(i)  + \".sav\"\n",
    "        filename = 'Gabor' + str(model) + str(num) + '.sav'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        print('fold '+ str(num))\n",
    "        print()\n",
    "        num += 1\n",
    "        \n",
    "\n",
    "\n",
    "        #confusion matrix\n",
    "        label_mapdisgust = ['anger','contempt','disgust','fear','hapiness','neutral','sad','surprise']\n",
    "        pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, pred)\n",
    "        #cm1 = cm.astype(np.float64) / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm_df = pd.DataFrame(cm, index = label_mapdisgust,\n",
    "                             columns = label_mapdisgust\n",
    "                            )\n",
    "        \n",
    "        final_cm = cm_df\n",
    "\n",
    "        #เเสดงผล confus matrix\n",
    "        emotion_labels = ['anger','contempt','disgust','fear','hapiness','neutral','sad','surprise']\n",
    "        plt.figure(figsize = (5,5))\n",
    "        #sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
    "        make_confusion_matrix(cm, figsize=(9,7), categories=emotion_labels)\n",
    "        plt.title('Emotion Classify')\n",
    "        plt.ylabel('True class')\n",
    "        plt.xlabel('Prediction class')\n",
    "        plt.show()\n",
    "        \n",
    "        #emotion_labels = ['anger','disgust','fear','hapiness','neutral','sad','surprise']\n",
    "        #plot_confusion_matrix(y_test, pred, classes=emotion_labels, normalize=True, title='Normalized confusion matrix {}'.format(model))\n",
    "        #plt.show()\n",
    "        \n",
    "        #Accurancy Score\n",
    "        def add_values_in_dict(sample_dict, key, list_of_values):\n",
    "            ''' Append multiple values to a key in \n",
    "            the given dictionary '''\n",
    "            if key not in sample_dict:\n",
    "                sample_dict[key] = list()\n",
    "            sample_dict[key].extend(list_of_values)\n",
    "            return sample_dict\n",
    "\n",
    "        #ใช้เก็บค่า TP FP FN TN ใน loop  confus matrix 7*7\n",
    "        TP2 = 0\n",
    "        FP2 = 0 \n",
    "        FN2 = 0\n",
    "        TN2 = 0\n",
    "        scor = {}\n",
    "        avg_scor = {}\n",
    "        ac = 0\n",
    "        pr = 0\n",
    "        re = 0\n",
    "        f1 = 0\n",
    "        sp = 0\n",
    "        for i in range(final_cm.shape[0]):\n",
    "          TP = final_cm.iloc[i,i]\n",
    "          FP =  final_cm.iloc[i,:].sum() - TP\n",
    "          FN =  final_cm.iloc[: ,i].sum() - TP\n",
    "          TN =  final_cm.sum().sum() - TP -FP - FN\n",
    "          TP2 += TP\n",
    "          FP2 += FP\n",
    "          FN2 += FN\n",
    "          TN2 += TN\n",
    "          Accuracy = (TP + TN)  /  final_cm.sum().sum()\n",
    "          Precision = TP / (TP + FP)\n",
    "          Recall = TP / (TP + FN)\n",
    "          Specificity = TN / (TN + FP)\n",
    "          F1_Score = (2* Precision * Recall ) / (Precision + Recall)\n",
    "            \n",
    "            \n",
    "          if i == 0:\n",
    "              sumAcc_anger.append(Accuracy)\n",
    "          if i == 1:\n",
    "              sumAcc_contempt.append(Accuracy)\n",
    "          if i == 2:\n",
    "              sumAcc_disgust.append(Accuracy)\n",
    "          if i == 3:\n",
    "              sumAcc_fear.append(Accuracy)\n",
    "          if i == 4:\n",
    "              sumAcc_hapiness.append(Accuracy)\n",
    "          if i == 5:\n",
    "              sumAcc_neutral.append(Accuracy)\n",
    "          if i == 6:\n",
    "              sumAcc_sad.append(Accuracy)\n",
    "          if i == 7:\n",
    "              sumAcc_surprise.append(Accuracy)\n",
    "          \n",
    "          print(\"Class:\",final_cm.index[i],\"Accuracy:\",Accuracy,\"Precision:\", Precision,\"Recall:\", Recall, \n",
    "                \"F1_Score:\", F1_Score, \"Specificity:\", Specificity )\n",
    "          print()\n",
    "\n",
    "          ac += Accuracy\n",
    "          pr += Precision\n",
    "          re += Recall\n",
    "          f1 += F1_Score\n",
    "          sp += Specificity\n",
    "\n",
    "          add_values_in_dict(scor, final_cm.index[i], [f'{Accuracy:.2f}',f'{Precision:.2f}',f'{Recall:.2f}',f'{F1_Score:.2f}',f'{Specificity:.2f}'])\n",
    "        print (\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format('','Accuracy','Precision','Recall','F1_Score','Specificity'))\n",
    "        for k, v in scor.items():\n",
    "            Accuracy, Precision, Recall,F1_Score,Specificity = v\n",
    "            print (\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(k, Accuracy, Precision, Recall,F1_Score,Specificity))\n",
    "              #pd.DataFrame(classification_report(model.y_train, model.pred)).T\n",
    "        add_values_in_dict(avg_scor,'macro avg',[f'{ac/8:.2f}' , f'{pr/8:.2f}' , f'{re/8:.2f}' , f'{f1/8:.2f}', f'{sp/8:.2f}'])\n",
    "        print()\n",
    "        for k, v in avg_scor.items():\n",
    "            ac, pr, re,f1,sp = v\n",
    "            print (\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(k, ac, pr, re,f1,sp))\n",
    "   \n",
    "        \n",
    "        Specificity = TN2 / (TN2 + FP2)\n",
    "        Sensitivity = TP2 / (FN2 + TP2)\n",
    "        print()  \n",
    "        print(\"Specificity\", f'{Specificity:.2f}')\n",
    "        print(\"Sensitivity\", f'{Sensitivity:.2f}')\n",
    "        #print(f\"Overall Accuracy: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print()\n",
    "        print(\"TP:\", TP2)\n",
    "        print(\"FN:\", FN2)\n",
    "        print(\"FP:\", FP2)\n",
    "        print(\"TN:\", TN2)\n",
    "\n",
    "        print()\n",
    "        Score = accuracy_score(y_test, pred)\n",
    "        mean_score.append(Score)\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "#สิ้นสุด loop 5 fold\n",
    "    print()\n",
    "    #print(f'accuracy = {accuracy}')\n",
    "    #print(f'Mean accuracy = {np.mean(accuracy)}')\n",
    "    #print(f'Max accuracy = {np.max(accuracy)}')\n",
    "    #print(f'Mean AUC = {mean_auc}')\n",
    "    score_np = np.array(mean_score)\n",
    "    print(f'Mean accuracy = {np.mean(mean_score) * 100:.2f}%')\n",
    "    print()\n",
    "    STD1 = np.std(sumAcc_anger)*100\n",
    "    print(\"The Standard diviation Accuracy of Anger :\", STD1,\"%\")\n",
    "    STD2 = np.std(sumAcc_disgust)*100\n",
    "    print(\"The Standard diviation Accuracy of Disgust :\", STD2,\"%\")\n",
    "    STD3 = np.std(sumAcc_fear)*100\n",
    "    print(\"The Standard diviation Accuracy of Fear :\", STD3,\"%\")\n",
    "    STD4 = np.std(sumAcc_hapiness)*100\n",
    "    print(\"The Standard diviation Accuracy of Hapiness :\", STD4,\"%\")\n",
    "    STD5 = np.std(sumAcc_neutral)*100\n",
    "    print(\"The Standard diviation Accuracy of Neutral :\", STD5,\"%\")\n",
    "    STD6 = np.std(sumAcc_sad)*100\n",
    "    print(\"The Standard diviation Accuracy of Sad :\", STD6,\"%\")\n",
    "    STD7 = np.std(sumAcc_surprise)*100\n",
    "    print(\"The Standard diviation Accuracy of Surprise :\", STD7,\"%\")\n",
    "    STD8 = np.std(sumAcc_contempt)*100\n",
    "    print(\"The Standard diviation Accuracy of Surprise :\", STD8,\"%\")\n",
    "\n",
    "    #print ROC curve in each emotion\n",
    "    for i in range(5) :\n",
    "        plt.plot(fpr1[i], tpr1[i], linestyle='--', \n",
    "                        label='%s fold %d (AUC=%0.2f)'%(classes[0],i,roc_auc1[i]))\n",
    "        i +=1\n",
    "    mean_tpr1 = np.mean(tprs1, axis=0)\n",
    "    mean_auc1 = auc(mean_fpr1, mean_tpr1)\n",
    "    std_auc1 = np.std(aucs1)\n",
    "    plt.plot(mean_fpr1, mean_tpr1, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f )' % (mean_auc1, std_auc1), lw=2, alpha=1)    \n",
    "    std_tpr = np.std(tprs1, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr1 + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr1 - std_tpr, 0)\n",
    "    plt.fill_between(\n",
    "        mean_fpr1,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\")\n",
    "    plt.plot([0,1],[0,1],'b--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('Multiclass ROC curve {}'.format(model))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    print()\n",
    "    \n",
    "\n",
    "    for i in range(5) :\n",
    "        plt.plot(fpr2[i], tpr2[i], linestyle='--', \n",
    "                        label='%s fold %d (AUC=%0.2f)'%(classes[1], i, roc_auc2[i]))\n",
    "        i += 1\n",
    "    mean_tpr2 = np.mean(tprs2, axis=0)\n",
    "    mean_auc2 = auc(mean_fpr2, mean_tpr2)\n",
    "    std_auc2 = np.std(aucs2)\n",
    "    plt.plot(mean_fpr2, mean_tpr2, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f )' % (mean_auc2, std_auc2), lw=2, alpha=1)    \n",
    "    std_tpr = np.std(tprs2, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr2 + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr2 - std_tpr, 0)\n",
    "    plt.fill_between(\n",
    "        mean_fpr2,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\")\n",
    "    plt.plot([0,1],[0,1],'b--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('Multiclass ROC curve {}'.format(model))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    print()\n",
    "                                                                           \n",
    "    for i in range(5) :\n",
    "        plt.plot(fpr3[i], tpr3[i], linestyle='--', \n",
    "                        label='%s fold %d (AUC=%0.2f)'%(classes[2],i,roc_auc3[i]))\n",
    "        i+=1\n",
    "    mean_tpr3 = np.mean(tprs3, axis=0)\n",
    "    mean_auc3 = auc(mean_fpr3, mean_tpr3)\n",
    "    std_auc3 = np.std(aucs3)\n",
    "    plt.plot(mean_fpr3, mean_tpr3, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f )' % (mean_auc3, std_auc3), lw=2, alpha=1)   \n",
    "    std_tpr = np.std(tprs3, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr3 + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr3 - std_tpr, 0)\n",
    "    plt.fill_between(\n",
    "        mean_fpr3,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\")\n",
    "    plt.plot([0,1],[0,1],'b--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('Multiclass ROC curve {}'.format(model))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    print()\n",
    "    \n",
    "    for i in range(5) :\n",
    "        plt.plot(fpr4[i], tpr4[i], linestyle='--', \n",
    "                        label='%s fold %d (AUC=%0.2f)'%(classes[3],i,roc_auc4[i]))\n",
    "        i+=1\n",
    "    mean_tpr4 = np.mean(tprs4, axis=0)\n",
    "    mean_auc4 = auc(mean_fpr4, mean_tpr4)\n",
    "    std_auc4 = np.std(aucs4)\n",
    "    plt.plot(mean_fpr4, mean_tpr4, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f )' % (mean_auc4, std_auc4), lw=2, alpha=1)     \n",
    "    std_tpr = np.std(tprs4, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr4 + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr4 - std_tpr, 0)\n",
    "    plt.fill_between(\n",
    "        mean_fpr4,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\")\n",
    "    plt.plot([0,1],[0,1],'b--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('Multiclass ROC curve {}'.format(model))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    print()\n",
    "                                            \n",
    "    for i in range(5) :\n",
    "        plt.plot(fpr5[i], tpr5[i], linestyle='--', \n",
    "                        label='%s fold %d (AUC=%0.2f)'%(classes[4],i,roc_auc5[i]))\n",
    "        i+=1\n",
    "    mean_tpr5 = np.mean(tprs5, axis=0)\n",
    "    mean_auc5 = auc(mean_fpr5, mean_tpr5)\n",
    "    std_auc5 = np.std(aucs5)\n",
    "    plt.plot(mean_fpr5, mean_tpr5, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f )' % (mean_auc5, std_auc5), lw=2, alpha=1)     \n",
    "    std_tpr = np.std(tprs5, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr5 + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr5 - std_tpr, 0)\n",
    "    plt.fill_between(\n",
    "        mean_fpr5,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\")\n",
    "    plt.plot([0,1],[0,1],'b--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('Multiclass ROC curve {}'.format(model))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    print()\n",
    "    \n",
    "    for i in range(5) :\n",
    "        plt.plot(fpr6[i], tpr6[i], linestyle='--', \n",
    "                        label='%s fold %d (AUC=%0.2f)'%(classes[5],i,roc_auc6[i]))\n",
    "        i+=1\n",
    "    mean_tpr6 = np.mean(tprs6, axis=0)\n",
    "    mean_auc6 = auc(mean_fpr6, mean_tpr6)\n",
    "    std_auc6 = np.std(aucs6)\n",
    "    plt.plot(mean_fpr6, mean_tpr6, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f )' % (mean_auc6, std_auc6), lw=2, alpha=1)   \n",
    "    std_tpr = np.std(tprs6, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr6 + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr6 - std_tpr, 0)\n",
    "    plt.fill_between(\n",
    "        mean_fpr6,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\")\n",
    "    plt.plot([0,1],[0,1],'b--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('Multiclass ROC curve {}'.format(model))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    print()\n",
    "    \n",
    "    for i in range(5) :\n",
    "        plt.plot(fpr7[i], tpr7[i], linestyle='--', \n",
    "                        label='%s fold %d (AUC=%0.2f)'%(classes[6],i,roc_auc7[i]))\n",
    "        i+=1\n",
    "    mean_tpr7 = np.mean(tprs7, axis=0)\n",
    "    mean_auc7 = auc(mean_fpr7, mean_tpr7)\n",
    "    std_auc7 = np.std(aucs7)\n",
    "    plt.plot(mean_fpr7, mean_tpr7, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f )' % (mean_auc7, std_auc7), lw=2, alpha=1) \n",
    "    std_tpr = np.std(tprs7, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr7 + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr7 - std_tpr, 0)\n",
    "    plt.fill_between(\n",
    "        mean_fpr7,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\")\n",
    "    plt.plot([0,1],[0,1],'b--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('Multiclass ROC curve {}'.format(model))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    print()\n",
    "\n",
    "    for i in range(5) :\n",
    "        plt.plot(fpr8[i], tpr8[i], linestyle='--', \n",
    "                        label='%s fold %d (AUC=%0.2f)'%(classes[7],i,roc_auc8[i]))\n",
    "        i+=1\n",
    "    mean_tpr8 = np.mean(tprs8, axis=0)\n",
    "    mean_auc8 = auc(mean_fpr8, mean_tpr8)\n",
    "    std_auc8 = np.std(aucs8)\n",
    "    plt.plot(mean_fpr8, mean_tpr8, color='blue',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f )' % (mean_auc8, std_auc8), lw=2, alpha=1) \n",
    "    std_tpr = np.std(tprs8, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr8 + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr8 - std_tpr, 0)\n",
    "    plt.fill_between(\n",
    "        mean_fpr8,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\")\n",
    "    plt.plot([0,1],[0,1],'b--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('Multiclass ROC curve {}'.format(model))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    print()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YX854cRrRXoo"
   },
   "outputs": [],
   "source": [
    "X = X1X2.to_numpy()\n",
    "y = y1y2.to_numpy()\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RU39ZDHYWCfB"
   },
   "outputs": [],
   "source": [
    "X = X1X3.to_numpy()\n",
    "y = y1y3.to_numpy()\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lQV72IrWESP"
   },
   "outputs": [],
   "source": [
    "X = X1X4.to_numpy()\n",
    "y = y1y4.to_numpy()\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghgalmexWGh3"
   },
   "outputs": [],
   "source": [
    "X = X1X5.to_numpy()\n",
    "y = y1y5.to_numpy()\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgWyiNTXWRnr"
   },
   "outputs": [],
   "source": [
    "X = X2X3.drop(['LABEL1'], axis = 1)\n",
    "y = X2X3['LABEL1']\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4j4-rWiWWgBT"
   },
   "outputs": [],
   "source": [
    "X = X2X4.drop(['LABEL1'], axis = 1)\n",
    "y = X2X4['LABEL1']\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXgbK1ybWhWO"
   },
   "outputs": [],
   "source": [
    "X = X2X5.drop(['LABEL1'], axis = 1)\n",
    "y = X2X5['LABEL1']\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAN733h2WjPB"
   },
   "outputs": [],
   "source": [
    "X = X3X4.drop(['LABEL1'], axis = 1)\n",
    "y = X3X4['LABEL1']\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlZkih-UWkSN"
   },
   "outputs": [],
   "source": [
    "X = X3X5.drop(['LABEL1'], axis = 1)\n",
    "y = X3X5['LABEL1']\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dX6Oix4ZWlW6"
   },
   "outputs": [],
   "source": [
    "X = X4X5.drop(['LABEL1'], axis = 1)\n",
    "y = X4X5['LABEL1']\n",
    "algo = [[KNeighborsClassifier(n_neighbors=5), 'KNeighborsClassifier']]\n",
    "            \n",
    "for a in algo:\n",
    "  model = a[0]\n",
    "    \n",
    "  model_roc_curve(X, y, model,cv)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2featurewrapper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
