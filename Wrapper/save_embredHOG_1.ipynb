{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJVXdCs7YGOX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import cv2, glob, random, math, numpy as np, dlib, itertools\n",
    "from skimage.feature import hog\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "#binarize the y_values\n",
    "#Lets encode target labels (y) with values between 0 and n_classes-1.\n",
    "#We will use the LabelEncoder to do this. \n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Import packages\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kYRbDBzYJYL"
   },
   "outputs": [],
   "source": [
    "# ใส่ ข้อมูลตรงนี้\n",
    "# เปลี่ยน path\n",
    "\n",
    "#X3 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/features_GABOR.npy') \n",
    "#y3 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/labels_GABOR.npy')\n",
    "\n",
    "#X4 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/features_HLAC.npy') \n",
    "#y4 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/labels_HLAC.npy')\n",
    "\n",
    "X5 = np.load('/content/drive/MyDrive/cn240/Feature_train_V4/feature_train/features_HOG.npy') \n",
    "y5 = np.load('/content/drive/MyDrive/cn240/Feature_train_V4/feature_train/labels_HOG.npy')\n",
    "\n",
    "#X1 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/features_LAND.npy') \n",
    "#y1 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/labels_LAND.npy')\n",
    "\n",
    "#X2 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/features_LBP.npy') \n",
    "#y2 = np.load('/content/drive/MyDrive/Colab Notebooks/feature Extraction(.npy)/labels_LBP.npy')\n",
    "\n",
    "#X_t = np.load('/content/drive/MyDrive/cn240/Feature_train_V4/feature_test/features_HOG.npy') \n",
    "#y_t = np.load('/content/drive/MyDrive/cn240/Feature_train_V4/feature_test/labels_HOG.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jq9Y4K-MdVBE"
   },
   "source": [
    "Tree base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2HB_4mu_EPo"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLg3yG2Qq1GC",
    "outputId": "3f6472f8-38cd-4c94-a286-d62cd64d2f31"
   },
   "outputs": [],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVTXZp4q-xHa",
    "outputId": "ef7180e0-488b-4d7b-8537-8b659a9b323d"
   },
   "outputs": [],
   "source": [
    "sel_ = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state = 0, n_jobs=-1))\n",
    "sel_.fit(df, y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3D6sBQD4x5vp"
   },
   "outputs": [],
   "source": [
    "filename = 'Sel_feat_v4' + '.sav'\n",
    "pickle.dump(sel_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6acuH1Iv_0T"
   },
   "outputs": [],
   "source": [
    "sel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbYsTJtEujkU",
    "outputId": "d3518c2d-2152-44e3-8237-52677397c10b"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JuFpYYn_Mw-"
   },
   "outputs": [],
   "source": [
    "selected_feat = df.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFWTnLX5vwHq",
    "outputId": "14ef277f-a322-4e1b-e72c-009c5489cea3"
   },
   "outputs": [],
   "source": [
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hX_psc0g_Odn",
    "outputId": "18cd2d96-5e16-4bbc-e1a4-5831c7cb07ca"
   },
   "outputs": [],
   "source": [
    "print(len(selected_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnitsMsQ_Q26"
   },
   "outputs": [],
   "source": [
    "df2 = sel_.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8p_7oQoOu9Wk",
    "outputId": "10424cde-a212-4be1-dff9-1082033dce96"
   },
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ejc81Tl12Gr0"
   },
   "outputs": [],
   "source": [
    "np.save('test_HOG_V4_embreded', df2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "save_embredHOG_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
