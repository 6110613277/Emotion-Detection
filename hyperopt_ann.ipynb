{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4deff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0329a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import random\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# For preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "# For LSTM model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm.keras import TqdmCallback\n",
    "# For FOPDT model\n",
    "from scipy.integrate import odeint\n",
    "# For hyperopt (parameter optimization)\n",
    "from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, RMSprop,Adagrad,Adadelta,Adamax,Nadam,SGD\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from itertools import cycle\n",
    "import keras\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "from skimage import color\n",
    "\n",
    "# Import libraries and packages\n",
    "import matplotlib as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers.core import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import time   # time1 = time.time(); print('Time taken: {:.1f} seconds'.format(time.time() - time1))\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "SEED = 42   # set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#โหลดดาต้า\n",
    "X = np.load(r'C:\\Users\\ASUS\\Documents\\datasci\\dataset\\detect\\Sample_HOG_embreded.npy') \n",
    "y = np.load(r'C:\\Users\\ASUS\\Documents\\datasci\\dataset\\detect\\Sample_labels_HOG.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#เเปลงเป็น binary\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y2 = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8\n",
    "Y = np_utils.to_categorical(y2, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "X,y = shuffle(X,Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.2,shuffle=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5354ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ใส่ค่า parameter ที่ต้องการหา \n",
    "from hyperopt.pyll.base import scope\n",
    "space = { \n",
    "            'layers': scope.int(hp.quniform('layers',1,3,1)),\n",
    "            'units1': scope.int(hp.quniform('units1',10,200,5)),\n",
    "            'units2': scope.int(hp.quniform('units2',10,200,5)),\n",
    "            'units3': scope.int(hp.quniform('units3',10,200,5)),\n",
    "\n",
    "            'dropout1': hp.quniform('dropout1',0.01,0.5,0.01),\n",
    "            'dropout2': hp.quniform('dropout2',0.01,0.5,0.01),\n",
    "            'dropout3': hp.quniform('dropout3',0.01,0.5,0.01),\n",
    "\n",
    "            'kernel1' : hp.choice('kernel1',['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']),\n",
    "            'kernel2' : hp.choice('kernel2',['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']),\n",
    "            'kernel3' : hp.choice('kernel3',['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']),\n",
    "\n",
    "            'activation1': hp.choice('activation1',['softmax','softsign','relu','elu','tanh','swish','sigmoid','leaky_relu']),\n",
    "            'activation2': hp.choice('activation2',['softmax','softsign','relu','elu','tanh','swish','sigmoid','leaky_relu']),\n",
    "            'activation3': hp.choice('activation3',['softmax','softsign','relu','elu','tanh','swish','sigmoid','leaky_relu']),\n",
    "    \n",
    "            'optimizer': hp.choice('optimizer1',['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']),\n",
    "            'batch_size' : scope.int(hp.quniform('batch_size',5,60,5)),\n",
    "            'epochs' : scope.int(hp.quniform('epochs',10,300,5)),\n",
    "            \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b7794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_nn(params):\n",
    "    # Generate data with given window\n",
    "    \n",
    "    model = Sequential()\n",
    "    model=keras.Sequential()\n",
    "    if params['layers'] == 1:\n",
    "        model.add(Dense(units=int(params['units1']),kernel_initializer=params['kernel1'],\n",
    "                                    input_shape=(7182,),\n",
    "                                    kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "        model.add(Dropout(params['dropout1']))\n",
    "        model.add(Activation(params['activation1']))\n",
    "        \n",
    "        \n",
    "    elif params['layers'] == 2:\n",
    "        model.add(Dense(units=int(params['units1']),kernel_initializer=params['kernel1'],\n",
    "                                    input_shape=(7182,),\n",
    "                                    kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "        model.add(Dropout(params['dropout1']))\n",
    "        model.add(Activation(params['activation1']))\n",
    "        ##layer2\n",
    "        model.add(Dense(units=int(params['units2']),kernel_initializer=params['kernel2']))\n",
    "        model.add(Dropout(params['dropout2']))\n",
    "        model.add(Activation(params['activation2']))\n",
    "        \n",
    "        \n",
    "    elif params['layers'] == 3:\n",
    "        model.add(Dense(units=int(params['units1']),kernel_initializer=params['kernel1'],\n",
    "                                    input_shape=(7182,),\n",
    "                                    kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "        model.add(Dropout(params['dropout1']))\n",
    "        model.add(Activation(params['activation1']))\n",
    "        ##layer2\n",
    "        model.add(Dense(units=int(params['units2']),kernel_initializer=params['kernel2']))\n",
    "        model.add(Dropout(params['dropout2']))\n",
    "        model.add(Activation(params['activation2']))\n",
    "        ##layer3\n",
    "        model.add(Dense(units=int(params['units3']),kernel_initializer=params['kernel3']))\n",
    "        model.add(Dropout(params['dropout3']))\n",
    "        model.add(Activation(params['activation3']))\n",
    "        \n",
    "        \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer=params['optimizer'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=15)\n",
    "#\n",
    "    result = model.fit(Xtrain, ytrain, verbose=0, validation_split=0.1,\n",
    "                       batch_size=params['batch_size'],\n",
    "                       epochs=params['epochs'],\n",
    "                       callbacks = [es,TqdmCallback(verbose=1)]\n",
    "                      )\n",
    "    \n",
    "    #get the lowest validation loss of the training epochs\n",
    "    validation_loss = np.amin(result.history['val_loss']) \n",
    "    print('Best validation loss of epoch:', validation_loss)\n",
    "\n",
    "    return {'loss': validation_loss, 'status': STATUS_OK, 'model': model, 'params': params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3bcfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(f_nn, space, algo=tpe.suggest, max_evals=100, trials=trials) #กำหนด max evals จำนวนครั้งวนซ้ำ\n",
    "\n",
    "best_model = trials.results[np.argmin([r['loss'] for r in trials.results])]['model']\n",
    "best_params = trials.results[np.argmin([r['loss'] for r in trials.results])]['params']\n",
    "\n",
    "worst_model = trials.results[np.argmax([r['loss'] for r in trials.results])]['model']\n",
    "worst_params = trials.results[np.argmax([r['loss'] for r in trials.results])]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6155d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eca3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9211a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b5c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7388b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
